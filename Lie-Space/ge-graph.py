import os

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pywt
from filterpy.kalman import KalmanFilter
from scipy.signal import savgol_filter, butter, filtfilt


# --------------------------
# æ•°æ®è¯»å–å‡½æ•°
# --------------------------
def read_and_process_data(filename):
    with open(filename, 'r') as file:
        lines = file.readlines()

    data_dict = {}
    current_key = None
    for line in lines:
        if 'Iteration' in line:
            current_key = int(line.split()[2])
            data_dict[current_key] = []
        elif line.strip() and not line.startswith('---'):
            try:
                data_dict[current_key].append(float(line.strip()))
            except:
                continue  # å¿½ç•¥æ— æ³•è§£æçš„è¡Œ

    max_length = max(len(v) for v in data_dict.values())
    df = pd.DataFrame({key: values + [np.nan] * (max_length - len(values))
                       for key, values in data_dict.items()})
    return df.T.values  # shape: (num_iterations, length_per_iter)


# -------
# æ»¤æ³¢å‡½æ•°
# -------
def butter_lowpass_filter(data, cutoff, fs, order=5):
    nyq = 0.5 * fs
    normal_cutoff = cutoff / nyq
    b, a = butter(order, normal_cutoff, btype='low', analog=False)
    y = filtfilt(b, a, data)
    return y


def kalman_filter(data, dt=1.0):
    kf = KalmanFilter(dim_x=2, dim_z=1)
    kf.x = np.array([data[0], 0])  # åˆå§‹çŠ¶æ€ (ä½ç½®å’Œé€Ÿåº¦)
    kf.F = np.array([[1, dt],
                     [0, 1]])  # çŠ¶æ€è½¬ç§»çŸ©é˜µ
    kf.H = np.array([[1, 0]])  # è§‚æµ‹çŸ©é˜µ
    kf.P *= 1000  # çŠ¶æ€åæ–¹å·®çŸ©é˜µ
    kf.R = 0.01  # è§‚æµ‹å™ªå£°åæ–¹å·®
    kf.Q = np.array([[0.001, 0],
                     [0, 0.001]])  # è¿‡ç¨‹å™ªå£°åæ–¹å·®

    filtered_data = []
    for z in data:
        kf.predict()
        kf.update(z)
        filtered_data.append(kf.x[0])
    return np.array(filtered_data)


def wavelet_denoising(data, wavelet, level=1):
    # Perform the wavelet decomposition
    coeff = pywt.wavedec(data, wavelet, mode='per')

    # Calculate the threshold for noise reduction
    sigma = np.median(np.abs(coeff[-level]) / 0.6745)
    uthresh = sigma * np.sqrt(2 * np.log(len(data)))

    # Apply the threshold to coefficients
    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='soft') for i in coeff[1:])

    # Reconstruct the signal using the modified coefficients
    return pywt.waverec(coeff, wavelet, mode='per')


# --------------------------
# è·¯å¾„åˆ†æå‡½æ•°
# --------------------------
# def analyze_path(dip, dt=10, window_length=21, polyorder=3):
#     dip_smooth = savgol_filter(dip, window_length=window_length, polyorder=polyorder)
#     velocities = [(dip_smooth[i + 1] - dip_smooth[i - 1]) / (2 * dt) for i in range(1, len(dip_smooth) - 1)]
#     accelerations = [(velocities[i + 1] - velocities[i - 1]) / (2 * dt) for i in range(1, len(velocities) - 1)]
#
#     avg_velocity = np.mean([abs(v) for v in velocities])
#     avg_acceleration = np.mean([abs(a) for a in accelerations])
#     kinetic_energy = np.mean([v ** 2 for v in velocities])
#     path_length = sum(abs(dip[i + 1] - dip[i]) for i in range(len(dip) - 1))
#
#     return {
#         "avg_velocity": avg_velocity,
#         "avg_acceleration": avg_acceleration,
#         "kinetic_energy": kinetic_energy,
#         "path_length": path_length,
#         "velocities": velocities,
#         "accelerations": accelerations
#     }


# --------------------------
# ç»˜å›¾å‡½æ•°
# --------------------------
def analyze_path(dip, dt=10, window_length=21, polyorder=3, fs=30, cutoff=3.667):
    dip_smooth = savgol_filter(dip, window_length=window_length, polyorder=polyorder)
    velocities = [(dip_smooth[i + 1] - dip_smooth[i - 1]) / (2 * dt) for i in range(1, len(dip_smooth) - 1)]

    # åº”ç”¨ä½é€šæ»¤æ³¢å™¨
    # filtered_velocities = butter_lowpass_filter(velocities, cutoff=cutoff, fs=20, order=3)
    # filtered_velocities = kalman_filter(velocities)
    filtered_velocities = wavelet_denoising(velocities, wavelet='db4', level=1)
    accelerations = [(filtered_velocities[i + 1] - filtered_velocities[i - 1]) / (2 * dt) for i in
                     range(1, len(filtered_velocities) - 1)]

    avg_velocity = np.mean([abs(v) for v in filtered_velocities])
    avg_acceleration = np.mean([abs(a) for a in accelerations])
    kinetic_energy = np.mean([v ** 2 for v in filtered_velocities])
    path_length = sum(abs(dip[i + 1] - dip[i]) for i in range(len(dip) - 1))

    return {
        "avg_velocity": avg_velocity,
        "avg_acceleration": avg_acceleration,
        "kinetic_energy": kinetic_energy,
        "path_length": path_length,
        "velocities": filtered_velocities,  # ä½¿ç”¨è¿‡æ»¤åçš„é€Ÿåº¦
        "accelerations": accelerations
    }


def plot_velocity_acceleration(results, labels, output_dir="plots"):
    os.makedirs(output_dir, exist_ok=True)

    for i, res in enumerate(results):
        plt.figure(figsize=(12, 5))

        # é€Ÿåº¦æ›²çº¿
        plt.subplot(1, 2, 1)
        plt.plot(res["velocities"], label=f'{labels[i]} Velocity', linewidth=1.5)
        plt.title("Velocity Magnitude")
        plt.xlabel("Time Step")
        plt.ylabel("Velocity")
        plt.legend()
        plt.grid(True)
        plt.ylim(-0.015, 0.015)  # ä¾‹å¦‚åªå±•ç¤º [-0.02, 0.02] çš„åŒºé—´

        # åŠ é€Ÿåº¦æ›²çº¿
        plt.subplot(1, 2, 2)
        plt.plot(res["accelerations"], label=f'{labels[i]} Acceleration', color='orange', linewidth=1.5)
        plt.title("Acceleration Magnitude")
        plt.xlabel("Time Step")
        plt.ylabel("Acceleration")
        plt.legend()
        plt.grid(True)
        plt.ylim(-0.015, 0.015)  # ä¾‹å¦‚åªå±•ç¤º [-0.02, 0.02] çš„åŒºé—´

        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, f"path_{labels[i]}_{1}.png"))
        plt.close()


# åœ¨ä¸»å‡½æ•°ä¸­è°ƒç”¨plot_velocity_accelerationä¹‹å‰ï¼Œç¡®ä¿æ•°æ®å·²ç»è¢«å……åˆ†å¹³æ»‘


# --------------------------
# ä¸»å‡½æ•°ï¼šæ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶
# --------------------------
def process_files(filenames, labels, output_file="analysis_results_{}.txt".format(1),
                  window_length=21, polyorder=3):
    results = []

    with open(output_file, 'w') as f:
        f.write(
            "Filename, Label, AvgVelocity, StdVelocity, AvgAcceleration, StdAcceleration, KineticEnergy, PathLength, RsdVelocity, RsdAcceleration\n")

        for filename, label in zip(filenames, labels):
            print(f"\nProcessing {filename} ({label})...")
            data = read_and_process_data(filename)

            all_avg_velocity = []
            all_avg_acceleration = []
            all_kinetic_energy = []
            all_path_length = []

            for i in range(data.shape[0]):
                dip = data[i]
                analysis = analyze_path(dip, window_length=window_length, polyorder=polyorder)

                all_avg_velocity.append(analysis["avg_velocity"])
                all_avg_acceleration.append(analysis["avg_acceleration"])
                all_kinetic_energy.append(analysis["kinetic_energy"])
                all_path_length.append(analysis["path_length"])

            # å–å¹³å‡å€¼ä½œä¸ºæ•´ä½“è·¯å¾„è´¨é‡
            avg_velocity = np.mean(all_avg_velocity)
            std_velocity = np.std(all_avg_velocity)
            avg_acceleration = np.mean(all_avg_acceleration)
            std_acceleration = np.std(all_avg_acceleration)
            rsd_velocity = avg_velocity / std_velocity
            rsd_acceleration = avg_acceleration / std_acceleration
            kinetic_energy = np.mean(all_kinetic_energy)
            path_length = np.mean(all_path_length)

            # å†™å…¥ç»“æœ
            f.write(
                f"{filename},{label},{avg_velocity:.6f},{std_velocity:.6f},{avg_acceleration:.6f},{std_acceleration:.6f},"
                f"{kinetic_energy:.6f},{path_length:.6f},{rsd_velocity:.6f},{rsd_acceleration:.6f}\n")

            # ä¿å­˜åˆ†æç»“æœç”¨äºç»˜å›¾
            results.append({
                "label": label,
                "avg_velocity": avg_velocity,
                "std_velocity": std_velocity,
                "avg_acceleration": avg_acceleration,
                "std_acceleration": std_acceleration,
                "kinetic_energy": kinetic_energy,
                "path_length": path_length,
                "velocities": analysis["velocities"],
                "accelerations": analysis["accelerations"]
            })

    return results


# --------------------------
# ä¸»ç¨‹åºå…¥å£
# --------------------------
if __name__ == "__main__":
    # è®¾ç½®å‚æ•°
    filenames = ["nn_generat_params_log1.txt", "sqc_generat_params_log1.txt"]  # æ›¿æ¢ä¸ºä½ çš„æ–‡ä»¶å
    labels = ["Path_A", "Path_B"]

    # æ‰§è¡Œåˆ†æ
    results = process_files(filenames, labels, window_length=21, polyorder=3)

    # å¯è§†åŒ–
    plot_velocity_acceleration(results, labels)

    print("\nâœ… åˆ†æå®Œæˆï¼")
    print("ğŸ“Š å›¾åƒå·²ä¿å­˜è‡³ 'plots/' æ–‡ä»¶å¤¹")
    print("ğŸ“„ æŒ‡æ ‡å·²è¾“å‡ºè‡³ 'analysis_results.txt'")
